{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Xiang Wang\n",
    "\n",
    "Student Netid: xw1173\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "1\\. Label each case as describing either data mining `(DM)`, or the use of the results of data mining `(USE)`.  [Replace `(ANS)` below.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) `(USE)` Choose customers who are most likely to respond to an on-line ad.\n",
    "\n",
    "b) `(DM)` Discover rules that indicate when an account has been defrauded.\n",
    "\n",
    "c) `(DM)` Find patterns indicating what customer behavior is more likely to lead to response to an on-line ad.\n",
    "\n",
    "d) `(USE)` Estimate probability of default for a credit application.\n",
    "\n",
    "e) `(USE)` Predict whether a customer is pregnant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Plumbing Inc. has been selling plumbing supplies for the last 20 years. The owner, Joe, decides that next year it is finally time to diversify by adding gardening tools to his products. Having had success using customer data to build predictive models to guide direct mail campaigns for special plumbing offers, he considers that data mining could help him to identify a subset of customers who should be good prospects for his new set of products. Is Joe ready to solve this as a supervised learning problem? What would you suggest as the target variable?  Be precise. Is there anything else that you would recommend that Joe do to achieve his business goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    I think Joe may not be ready to solve it yet if he does not have the labled training data, while I do think he may have clients' related features like :\n",
    "    1. Different kinds of plumbing supplies that are related to garden?\n",
    "    2. Location / Acceptable price level / Total purchase amount / rate of taking mail offer etc.\n",
    "    yet he may miss the training data on the target variable, which may be the likelyhood of buying gardening tools (through mailing offers maybe). \n",
    "    \n",
    "    I would recomment him to first do some data preparation by mailing special gardening tools offer(which should have product good enough and price low enough to attract any client having garden using gardening tools) to a subset of his past clients and collect the result on which clients do take the offer as labeled data.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "This is a hands-on task where we build a tree-structured predictive model as discussed in class and in the book. For this part, we will be using the data in `data/cell2cell_data_80_percent.csv`.\n",
    "\n",
    "These historical data consist of 31,892 customers: 15,855 customers that churned (i.e., left the company) and 16,036 that did not churn (see the `\"churndep\"` variable). Here are the data set's 11 attributes describing the customers: \n",
    "\n",
    "```\n",
    "Pos.  Var. Name  Var. Description\n",
    "----- ---------- --------------------------------------------------------------\n",
    "1     revenue    Mean monthly revenue in dollars\n",
    "2     outcalls   Mean number of outbound voice calls\n",
    "3     incalls    Mean number of inbound voice calls\n",
    "4     months     Months in Service\n",
    "5     eqpdays    Number of days the customer has had his/her current equipment\n",
    "6     webcap     Handset is web capable\n",
    "7     marryyes   Married (1=Yes; 0=No)\n",
    "8     travel     Has traveled to non-US country (1=Yes; 0=No)\n",
    "9     pcown      Owns a personal computer (1=Yes; 0=No)\n",
    "10    creditcd   Possesses a credit card (1=Yes; 0=No)\n",
    "11    retcalls   Number of calls previously made to retention team\n",
    "```\n",
    "\n",
    "The 12th column, the target variable `\"churndep\"`, equals 1 if the customer churned, and 0 otherwise. \n",
    "\n",
    "\n",
    "**Don't forget to exclude the target variable `\"churndep\"` when fitting your models. You don't want to include the target when fitting!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data into a pandas `DataFrame()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        revenue  outcalls  incalls  months  eqpdays  webcap  marryyes  travel  \\\n",
       "0        83.53     20.00     1.00      31      745       1         0       0   \n",
       "1        29.99      0.00     0.00      52     1441       0         0       0   \n",
       "2        37.75      2.67     0.00      25      572       0         0       0   \n",
       "3         5.25      0.00     0.00      45     1354       0         0       0   \n",
       "4        42.71      8.67     0.00      27      224       1         0       0   \n",
       "5        53.69     15.00     2.33      23      267       1         0       0   \n",
       "6        33.66      8.33     0.00      31      933       1         0       0   \n",
       "7        52.56     80.00    31.67      33      402       1         0       0   \n",
       "8        22.50      8.67     2.67      37      243       1         0       0   \n",
       "9        98.47     24.67     3.33      35       13       0         0       1   \n",
       "10        7.82      0.00     0.00      24      561       0         0       0   \n",
       "11       25.14     15.00     1.00      25      743       1         0       0   \n",
       "12      131.09     76.67     7.00      25      740       1         1       0   \n",
       "13       10.00      0.00     0.00      54     1636       0         1       0   \n",
       "14        5.00      0.00     0.00      53     1584       0         1       1   \n",
       "15       30.69      1.33     0.00      25      709       1         0       0   \n",
       "16       69.11     18.00     2.67      48     1430       0         0       0   \n",
       "17       40.07      3.67     0.00      42     1278       0         0       0   \n",
       "18       51.22      1.00     0.33      44     1346       0         1       0   \n",
       "19       84.92     67.00     0.33      15      451       1         1       0   \n",
       "20       12.21      0.00     0.00      35      540       0         1       0   \n",
       "21      170.92     35.00     0.33      10      302       1         1       0   \n",
       "22      199.00     88.67    40.00      19      368       1         0       0   \n",
       "23       16.14      0.00     0.00      44     1324       0         0       0   \n",
       "24       61.72     19.33    39.00      16      464       1         0       0   \n",
       "25      150.00      1.67     1.00      11      295       1         0       0   \n",
       "26      113.78     14.00     0.00      12      341       1         0       0   \n",
       "27       71.38      0.33     0.00      27      345       0         1       0   \n",
       "28       89.58     18.67    12.00      14      417       1         0       0   \n",
       "29       37.49     18.00    33.67      32      718       1         1       0   \n",
       "...        ...       ...      ...     ...      ...     ...       ...     ...   \n",
       "31861    55.51     20.33     1.67      54       45       1         0       0   \n",
       "31862   108.15     29.33    76.67      34        5       1         0       0   \n",
       "31863    87.52     72.00    30.67      55       99       1         0       0   \n",
       "31864    10.70      7.00    10.67      51       80       1         1       0   \n",
       "31865    39.99      2.67     0.67      53       37       1         1       0   \n",
       "31866    45.85     11.33     0.67      52       11       1         0       0   \n",
       "31867    36.39      4.67     0.00      51        6       1         1       0   \n",
       "31868    76.47     67.00    32.67      48       25       1         1       0   \n",
       "31869    45.95     23.33    73.33      47       62       1         0       0   \n",
       "31870    82.18    188.33   116.33      31       81       1         0       0   \n",
       "31871   140.03    239.00   190.67      24       66       1         0       0   \n",
       "31872    39.54     38.00    26.67      48       26       1         1       0   \n",
       "31873    83.58     34.00    21.33      54       16       1         1       0   \n",
       "31874    55.79     11.67    20.00      57       65       1         0       0   \n",
       "31875   157.86    286.00   282.67      20      262       1         0       0   \n",
       "31876   107.60    217.33   113.33      45      157       1         0       0   \n",
       "31877   107.42    119.33   175.00      42      175       1         0       0   \n",
       "31878   291.26    389.67   173.00      48      126       1         0       0   \n",
       "31879   110.33    389.00   218.00      23       92       1         0       0   \n",
       "31880    51.99    164.00    48.67      49        3       1         0       0   \n",
       "31881     1.63      0.00     0.00      59       10       1         1       1   \n",
       "31882    72.96     60.00    86.00      47       68       1         0       0   \n",
       "31883   226.52     74.67   304.00      17      132       1         0       0   \n",
       "31884    99.15    251.67   174.33      28       91       1         1       0   \n",
       "31885   110.73    224.67   184.00      47      267       1         1       0   \n",
       "31886   185.30    178.67   171.00      41       44       1         1       0   \n",
       "31887   167.59    141.33   283.67      17       28       1         0       0   \n",
       "31888   151.49    128.67   175.33      47        9       1         1       0   \n",
       "31889   125.42     90.00   336.67      18       79       1         0       0   \n",
       "31890   206.67    396.00   404.00      14      126       1         0       0   \n",
       "\n",
       "       pcown  creditcd  retcalls  churndep  \n",
       "0          0         0         4         1  \n",
       "1          1         1         3         1  \n",
       "2          1         1         3         1  \n",
       "3          0         0         2         1  \n",
       "4          0         0         3         1  \n",
       "5          0         1         3         1  \n",
       "6          0         0         2         1  \n",
       "7          0         1         3         1  \n",
       "8          0         0         3         1  \n",
       "9          1         1         3         1  \n",
       "10         0         0         2         1  \n",
       "11         0         0         2         1  \n",
       "12         0         1         2         1  \n",
       "13         0         1         1         1  \n",
       "14         1         1         1         1  \n",
       "15         0         1         2         1  \n",
       "16         0         1         1         1  \n",
       "17         0         0         1         1  \n",
       "18         0         1         1         1  \n",
       "19         0         1         2         1  \n",
       "20         0         1         2         1  \n",
       "21         0         1         2         1  \n",
       "22         0         0         2         1  \n",
       "23         0         1         1         1  \n",
       "24         0         0         2         1  \n",
       "25         1         1         2         1  \n",
       "26         0         1         2         1  \n",
       "27         0         1         2         1  \n",
       "28         0         1         2         1  \n",
       "29         0         1         2         1  \n",
       "...      ...       ...       ...       ...  \n",
       "31861      0         1         0         0  \n",
       "31862      1         1         0         0  \n",
       "31863      0         1         0         0  \n",
       "31864      1         1         0         0  \n",
       "31865      0         1         0         0  \n",
       "31866      0         1         0         0  \n",
       "31867      1         1         0         0  \n",
       "31868      0         1         0         0  \n",
       "31869      0         0         0         0  \n",
       "31870      0         1         0         0  \n",
       "31871      0         0         0         0  \n",
       "31872      0         1         0         0  \n",
       "31873      0         1         0         0  \n",
       "31874      0         1         0         0  \n",
       "31875      0         0         0         0  \n",
       "31876      0         1         0         0  \n",
       "31877      0         0         0         0  \n",
       "31878      0         1         0         0  \n",
       "31879      0         0         0         0  \n",
       "31880      0         1         0         0  \n",
       "31881      1         1         0         0  \n",
       "31882      0         1         0         0  \n",
       "31883      0         0         0         0  \n",
       "31884      0         1         0         0  \n",
       "31885      0         1         0         0  \n",
       "31886      1         1         0         0  \n",
       "31887      0         0         0         0  \n",
       "31888      0         1         0         0  \n",
       "31889      0         0         0         0  \n",
       "31890      0         0         0         0  \n",
       "\n",
       "[31891 rows x 12 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/cell2cell_data_80_percent.csv')\n",
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Using the following two functions for Entropy and Information Gain (don't forget to run this cell!), figure out what is the maximum information gain for each feature. Make a bar plot with feature names along the x-axis and maximum information gain on the y-axis. Which feature gives the largest information gain? Don't forget that some of the features are binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def entropy(target):\n",
    "    '''\n",
    "        Computes the entropy for a set of instances (that's needed is the values of the target variable)\n",
    "        Presumes the target values are class indexes -- integers\n",
    "        Thus, target is an array of integers\n",
    "    '''\n",
    "    # Get the number of instances\n",
    "    n = len(target)\n",
    "    # Count how frequently each unique target value occurs using the numpy function \n",
    "    counts = np.bincount(target).astype(float)\n",
    "    # Initialize entropy\n",
    "    entropy = 0\n",
    "    \n",
    "    # Otherwise, for each possible value, update entropy; use zero for 0 log 0\n",
    "    for count in counts:\n",
    "        if count == 0:\n",
    "            entropy += 0\n",
    "        else:\n",
    "            entropy += math.log(count/n, 2) * count/n\n",
    "    # Return entropy\n",
    "    return -1 * entropy\n",
    "\n",
    "\n",
    "def information_gain(feature, threshold, target):\n",
    "    '''\n",
    "    This function takes three things:\n",
    "    feature - A list of all the values this feature takes on, in some instance order, e.g. data['revenue']\n",
    "    threshold - A number at which to threshold a continuous variable, e.g. 1.2\n",
    "    target - A list of all the target values, in the same order as feature, e.g. data['churndep']\n",
    "    '''\n",
    "    # Using numpy arrays makes this slightly easier\n",
    "    target = np.array(target)\n",
    "    feature = np.array(feature)\n",
    "    # Record if each feature value is above the threshold\n",
    "    feature = (feature <= threshold)\n",
    "    # Initialize information gain with the parent entropy\n",
    "    ig = entropy(target)\n",
    "    # For each side of the threshold, update the information gain\n",
    "    for level, count in zip([0, 1], np.bincount(feature).astype(float)):\n",
    "        ig -= count/len(feature) * entropy(target[feature == level])\n",
    "    # Return information gain\n",
    "    return ig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGZCAYAAADPdZjNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f823a44aef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features = []\n",
    "thresholds = []\n",
    "igs = []\n",
    "isBinary = set([\"marryyes\", \"travel\", \"pcown\", \"creditcd\", \"webcap\"])\n",
    "target = data['churndep']\n",
    "for feature in data.columns:\n",
    "    if feature == 'churndep':\n",
    "        continue\n",
    "    features.append(feature)\n",
    "    fValue = data[feature]\n",
    "    minValue = fValue.min()\n",
    "    maxValue = fValue.max()\n",
    "    ig = 0\n",
    "    threshold = 0\n",
    "    if feature in isBinary:\n",
    "        # consider two value\n",
    "        ig0 = information_gain(fValue, minValue, target)\n",
    "        ig1 = information_gain(fValue, maxValue, target)\n",
    "        if ig0 > ig1:\n",
    "            ig = ig0\n",
    "            threshold = minValue\n",
    "        else:\n",
    "            ig = ig1\n",
    "            threshold = maxValue\n",
    "    else:\n",
    "        for value in (minValue, maxValue + 0.01, 0.01):\n",
    "            ig0 = information_gain(fValue, value, target)\n",
    "            if ig0 > ig:\n",
    "                ig = ig0\n",
    "                threshold = value\n",
    "    igs.append(ig)\n",
    "    thresholds.append(threshold)\n",
    "\n",
    "# Use the lists we created to plot\n",
    "\n",
    "plt.bar(range(len(features)), igs)\n",
    "plt.xticks(range(len(features)), features, rotation=70)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Is the relationship between the top 3 most important features negative or positive? If your boss asked you to \"explain the top 3 drivers of churn,\" how would you interpret the relationship between these 3 features and the churn outcome that you find in these results?  \n",
    "\n",
    "What \"real-life\" connection can you draw between each variable and churn?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featuresToCheck' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a27e92beda70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeaturesToCheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'featuresToCheck' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "featuresToCheck = [\"webcap\", \"retcalls\", \"incalls\"]\n",
    "num_users = len(data.index)\n",
    "\n",
    "for feature in featuresToCheck:\n",
    "    index = features.index(feature)\n",
    "    print(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Now build and fit a tree-structured model using `DecisionTreeClassifier()` [(manual page)](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) using the 11 attributes to **predict the `\"churndep\"` target** variable. Make sure to use `criterion='entropy'` when instantiating an instance of `DecisionTreeClassifier()`.  For this assignment, use a moderately shallow tree (e.g., `max_depth=3`). For all other settings you should use the default options (this means you don't have to set anything else).  See the examples from the class notebooks. **Create this model in a variable called: \"tree_model\"**\n",
    "\n",
    "**Remember, don't forget to exclude the target variable `\"churndep\"` when fitting your models. You don't want to fit on the target!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-bc8da97ad461>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-bc8da97ad461>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    tree_model =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "tree_model = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Now visualize your tree structure.  Would the data-driven model lead you to change or update any of your interpretations of the relationships between the variables and churn?\n",
    "\n",
    "(Recall that we visualized a tree in class.  To use that code, you'll need some libraries and the directory you are working in should have an \"images\" subdirectory, as that is where the tree image is stored by the code.  Also, it doesn't work well to visualize a huge tree.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "# A function that gives a visual representation of the decision tree\n",
    "def Decision_Tree_Image(decision_tree, feature_names, name=\"temp\"):\n",
    "    # Export our decision tree to graphviz format\n",
    "    dot_file = tree.export_graphviz(decision_tree.tree_, out_file='images/' + name + '.dot', feature_names=feature_names)\n",
    "    # Call graphviz to make an image file from our decision tree\n",
    "    os.system(\"dot -T png images/\" + name + \".dot -o images/\" + name + \".png\")\n",
    "    # Return the .png image so we can see it\n",
    "    return Image(filename='images/' + name + '.png')\n",
    "\n",
    "\n",
    "\n",
    "# YOU SHOULD HAVE CREATED TREE_MODEL AND DATA VARIABLES BEFORE !!!!\n",
    "\n",
    "Decision_Tree_Image(tree_model, data.drop(['churndep'], axis=1).columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Load in another data set `data/cell2cell_data_20_percent.csv`. This data is of the same format as the other file we read in. Using the classifier built and fit above, predict `\"churndep\"` on the original data and the new data that you just loaded in. How well does it predict? (I.e., what is the accuracy on each data set?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn   # This library will help to get the values\n",
    "\n",
    "\n",
    "data_new = \n",
    "\n",
    "tree_data_accuracy = \n",
    "tree_new_data_accuracy = \n",
    "\n",
    "\n",
    "# This line will be used for grading. DO NOT REMOVE IT. Make sure it prints out the correct value!!!\n",
    "print (\"Data and data_new accuracy = %.4f and %.4f\" % (tree_data_accuracy, tree_new_data_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Create your own training/test split.  First use pandas to create one unique data frame **combining** the 80_percent and the 20_percent dataframes. \n",
    "\n",
    "Then, write the code to split that data frame into 2 new, random samples **without replacement**. You should have at the end a new random data frame called \"train_df\" with 80% of the data and another dataframe called \"test_df\" including the rest (20%) of the data. You may use any `random` function from numpy that suits, but **DO NOT** use functions from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set randomness if you want to test it with the same answer\n",
    "\n",
    "#import numpy as np\n",
    "#np.random.seed(841)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DON'T FORGET TO LOOK AT THE SIZE OF YOUR COMBINED DATA FRAME  \n",
    "# YOU CAN USE THE FUNCTION \"SHAPE\" FOR THIS:  PRINT ( MY_DATAFRAME_COMBINED.SHAPE )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. From the new train/test split, what is the generalization accuracy of a learned classification tree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "new_tree_train_accuracy = \n",
    "new_tree_test_accuracy = \n",
    "\n",
    "\n",
    "# This line will be used for grading. DO NOT REMOVE IT. Make sure it prints out the correct value!!!\n",
    "print (\"Train_df and test_df accuracy (my split) = %.4f and %.4f\" % (new_tree_train_accuracy, new_tree_test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "The options we chose for your tree may not be optimal. We need to analyze whether tuning the parameters can improve the accuracy of the classifier.  For the following options `max_depth`, `min_samples_split`, and `min_samples_leaf`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Generate a range of 10 values of each that make sense to test (To select these numbers: Think about the number of observations that you have)\n",
    "\n",
    "[ Hint: exponentially increasing values for the parameters is a good approach ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "min_samples_split_values = []\n",
    "min_samples_leaf_values = []\n",
    "max_depth_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. For the values of `max_depth`, `min_samples_split`, and `min_samples_leaf` you chose in 3.1 build a new decision tree classifier **(on the *original* data we read in, stored in _`data`_ with the CSV information)** and record the classifier's accuracy ON both, the original train (data) and test (data\\_new). You should now generate three plots, each with 10 points for the original data and 10 points for the new data. The values you chose are on the x-axis, the accuracies you calculated are on the y-axis, and there will be two lines/curves per plot (one for `data` and the other for `data_new`).\n",
    "\n",
    "[Hint: for `min_samples_split` and `min_samples_leaf` you may want to visualize your plot with a **log scale** on the x-axis.  Also note that the fitting curve will be \"backwards\" for those two parameters, as we would expect more fitting with smaller values.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# MIN SAMPLES SPLIT GRAPH\n",
    "\n",
    "accuracies = []\n",
    "accuracies_new = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MIN SAMPLES LEAF GRAPH\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "accuracies_new = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAX DEPTH GRAPH\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "accuracies_new = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Now let's try fitting some linear models: a logistic regression (`sklearn.linear_model.LogisticRegression()`, [manual](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) and SVM (`sklearn.svm.LinearSVC()`, [manual](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)). For each of these models, fit them on the first set of data we read in (the TRAIN which is stored in `data`) and report the accuracy on both sets of data we read first (the train in `data` and the test in `data_new`). \n",
    "\n",
    "When fitting each model, you should keep all parameters at their defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "logistic_regression_original_accuracy = \n",
    "logistic_regression_new_accuracy = \n",
    "\n",
    "svm_original_accuracy = \n",
    "svm_new_accuracy = \n",
    "\n",
    "\n",
    "\n",
    "# These lines will be used for grading. DO NOT REMOVE THEM. Make sure they print out the correct values!!!\n",
    "print (\"Original and new logistic regression accuracy = %.4f and %.4f\" % (logistic_regression_original_accuracy, logistic_regression_new_accuracy))\n",
    "print (\"Original and new SVM accuracy = %.4f and %.4f\" % (svm_original_accuracy, svm_new_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Now, let's compare this results with YOUR **new split created (train_df and test_df)**. \n",
    "\n",
    "Fit the same models (logistic regression and SVM) on these random data frames and report the accuracy on both sets (train_df and test_df). When fitting each model, you should keep all parameters as their defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "logistic_regression_original_accuracy = \n",
    "logistic_regression_new_accuracy = \n",
    "\n",
    "svm_original_accuracy = \n",
    "svm_new_accuracy = \n",
    "\n",
    "\n",
    "\n",
    "# These lines will be used for grading. DO NOT REMOVE THEM. Make sure they print out the correct values!!!\n",
    "print (\"Original and new logistic regression accuracy = %.4f and %.4f\" % (logistic_regression_original_accuracy, logistic_regression_new_accuracy))\n",
    "print (\"Original and new SVM accuracy = %.4f and %.4f\" % (svm_original_accuracy, svm_new_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "5\\. Compare the results of the original split and your random split.  Are they the different?  What do you conclude from this comparison about the original split of the data that you were given? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "6\\. Compare the results of the linear models and the tree-structured models.  What do you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Your answer here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
